{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5deee5c6-bc09-4af4-bcc4-8fccc82e0986",
   "metadata": {},
   "source": [
    "## Lab 5 Part II: Plotting Contoured Upper-Air Data\n",
    "<br /><br />\n",
    "\n",
    "In this part of the tutorial, we are going to plot station data (observations) at 500 hPa and GFS model-derived 500 hPa geopotential height isopleths.\n",
    "<br />\n",
    "### Module Documentation\n",
    "\n",
    "1. Siphon IAStateUpperAir: https://unidata.github.io/siphon/latest/api/simplewebservice.html#module-siphon.simplewebservice.iastate\n",
    "2. Xarray Dataset: https://docs.xarray.dev/en/stable/generated/xarray.Dataset.html\n",
    "3. Matplotlib Pyplot: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n",
    "4. Caropy crs: https://scitools.org.uk/cartopy/docs/latest/reference/crs.html\n",
    "5. Cartopy Feature: https://scitools.org.uk/cartopy/docs/latest/matplotlib/feature_interface.html\n",
    "6. Matplotlib Colors: https://matplotlib.org/stable/gallery/color/named_colors.html\n",
    "7. Matplotlib Contour: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.contour.html\n",
    "8. Matplotlib Barbs: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.barbs.html\n",
    "9. Scipy Gaussian Filter: https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter.html\n",
    "\n",
    "\n",
    "\n",
    "If you have any questions about the code below, feel free to reach out to me at mpvossen@uwm.edu. I am always willing to further explain the code. <br /> <br />\n",
    "\n",
    "---\n",
    "\n",
    "<br />\n",
    "1. As usual, we start by importing the modules we need for our Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0778ac-d8ad-43a7-bef6-cf6d5e8a9cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the dates and time code(datetime), import the date and time reading capabilities (datetime)\n",
    "from datetime import datetime\n",
    "\n",
    "#from the metpy (metpy) module's ability to read and write files (.io), import the function to add latitude and longitude data for upper-air and surface station data (import add_station_lat_lon)\n",
    "from metpy.io import add_station_lat_lon\n",
    "\n",
    "#from metpy's plotting abilities (metpy.plots), import the abilities to create a station plot (StationPlot) and the sky cover symbols (sky_cover).\n",
    "from metpy.plots import StationPlot, sky_cover\n",
    "\n",
    "#import the module numpy and save it to np\n",
    "import numpy as np\n",
    "\n",
    "#import the cartopy (cartopy) module's coordinate reference system (.crs) and save it to the variable crs\n",
    "import cartopy.crs as crs\n",
    "\n",
    "#import the cartopy (cartopy) module's ability to plot geographic data (.feature) and save it to the variable cfeature \n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "#import the pyplot submodule from the matplotlib module\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from the scipy module's ndimage submodule, import the function gaussian_filter\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "#import the module xarray and save it to xr\n",
    "import xarray as xr\n",
    "\n",
    "#from the siphon module's (from siphon) web data downloader (.simplewebservice) specifically for Iowa State (.iastate) data, import the upper air downloader (import IAStateUpperAir)\n",
    "from siphon.simplewebservice.iastate import IAStateUpperAir\n",
    "\n",
    "#import the sys module to tap into the underlying Linux operating system\n",
    "import sys\n",
    "\n",
    "#One of our modules is not in the standard location, so we need to define the location of the Extra_Modules directory where there are some homemade modules.\n",
    "sys.path.insert(0, '/srv/data/shared_notebooks/Synoptic1-AtmSci360/Extra_Modules/')\n",
    "\n",
    "#from the module min_max (available through the module path defined above), import the function plot_maxmin_points\n",
    "from min_max import plot_maxmin_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1804491f-e6bf-498b-ad49-b553d443f7e8",
   "metadata": {},
   "source": [
    "<br /><br />\n",
    "2.  We need to set up two variables, one for the time at which we want data and the other for the isobaric level at which we want data (in hPa).  In the section below, define a datetime object for August 30th, 2021 1200 UTC and a variable containing the desired isobaric level (here, 500 hPa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eadfcb-37fc-4c2a-a70b-16b5d0fdbdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_time = \n",
    "level = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e97da-bc57-4c41-950a-e0f673826570",
   "metadata": {},
   "source": [
    "<br /><br />\n",
    "3. We again process the data in a function since we will be creating multiple plots.  Watch out in the comments for areas that you need to fill in or complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30529a5e-5e13-4f55-aef0-f561b847f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Below I define a function to retrieve and process upper-air data.  This function downloads rawinsonde data, opens the corresponding\n",
    "GFS analysis data, retains only the desired pressure level, and removes missing values from the rawinsonde data.\n",
    "\n",
    "\n",
    "INPUT:\n",
    "    level : INTEGER\n",
    "        The level in hPa at which you want upper-air data.\n",
    "    time : DATETIME\n",
    "        The time at which you would like upper-air data.\n",
    "    \n",
    "OUTPUT:\n",
    "    obs_data : PANDAS DATAFRAME\n",
    "        Dataframe containing your processed rawinsonde data\n",
    "    leveled_data : XARRAY DATASET\n",
    "        The xarray containing your processed GFS analysis data\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def process_upper_air_data(level, time):\n",
    "    \"\"\"\n",
    "    Specify the location of the upper-air data on the JupyterHub.\n",
    "    \"\"\"\n",
    "    lab_data_loc = \"/data/AtmSci360/Lab_5/\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Open the GFS data using xarray.  Since the data are once again GRIB-formatted data, we can use xarray the same way we did in Lab 4.\n",
    "    \"\"\"\n",
    "    model_data = xr.open_dataset(f\"{lab_data_loc}{time:%m%d%y_%H}_gfs.grib2\", engine='cfgrib', filter_by_keys={'typeOfLevel': 'isobaricInhPa'})\n",
    "    \n",
    "    \"\"\"\n",
    "    We only want data at a single isobaric level.  Limit the data in the xarray to only this specified level.\n",
    "    \"\"\"\n",
    "    leveled_data =\n",
    "    \n",
    "    \"\"\"\n",
    "    We also need upper-air observations, so let's download rawinsonde data from Iowa State for the single specified level, as we did in Lab 2.\n",
    "    \"\"\"\n",
    "    obs_data = IAStateUpperAir.request_all_data(map_time, level)\n",
    "    \n",
    "    \"\"\"\n",
    "    Like in Lab 2, the downloaded Iowa State rawinsonde data do not have latitude and longitude information for each station.  \n",
    "    The line below adds the latitude and longitude to each station using MetPy's add_stations_lat_lon function.\n",
    "    \"\"\"\n",
    "    obs_data = add_station_lat_lon(obs_data)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    The MetPy add_station_lat_lon does not have every station, however, and so some stations are missing their latitude and \n",
    "    longitude values.  The command below drops all stations that do not have a latitude and/or longitude value.\n",
    "    \"\"\"\n",
    "    obs_data = obs_data.dropna(how='any', subset=['latitude', 'longitude'])\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    This line returns the observation data and model data after the function ends.\n",
    "    \"\"\"\n",
    "    return obs_data, leveled_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33389dc-2f95-4b85-b234-00737f2569aa",
   "metadata": {},
   "source": [
    "<br /><br />\n",
    "4. In the cell below, call the function we created to process data using the level and time you specified earlier in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2f7c7-136e-47c0-b7b1-af14254d7c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81c969bd-fe40-4a79-84c4-e20d3631181a",
   "metadata": {},
   "source": [
    "<br /><br />\n",
    "5. Since we are making multiple plots, we also need to create a plot function.  Again, watch out in the comments for areas that you need to fill in or complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42d3b5-8cde-45b8-b795-dbdc83a04ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Below I define a function to plot upper-air data.  This function creates station-model plots for the observations and\n",
    "uses GFS data to draw geopotential height isopleths.\n",
    "\n",
    "\n",
    "INPUT:\n",
    "    obs_data : PANDAS DATAFRAME\n",
    "        The dataframe containg your rawinsonde data\n",
    "    model_data : XARRAY DATASET\n",
    "        The xarray dataset containing your GFS analysis.\n",
    "    date : DATETIME\n",
    "        The time at which your upper-air data are valid.\n",
    "    level : INTEGER\n",
    "        The level in hPa at which you want upper-air data.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def plot_upper_air(obs_data, model_data, date, level):\n",
    "    \n",
    "    \"\"\"\n",
    "    Setup a Lambert Conformal Conic Projection centered at 35째N and 95째W.  Have the cone of the Lambert Conformal Conic projection intersect the Earth at 27.5째N and 42.5째N.\n",
    "    \"\"\"\n",
    "    proj = \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Create a figure with a size of 1000px x 1500px and a resolution of 300 dots per inch,\n",
    "    then set up an axes object (named ax) using the projection we previously defined for our map.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Add the appropriate amount of geographic data.  Be sure you follow \"good map\" suggestions with the geographic data styling.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Limit the map to between 125째-65째W longitude and 23째-60째N latitude.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Setup the station plots for the upper-air observations.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Add temperature, dewpoint, wind, and geopotential height (in decameters) in the appropriate locations with appropriate formatting.  \n",
    "    Make sure that your data displayed in your station plot are clear and easy to read.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Like in Lab 2, we need to make the center sky cover symbol an open circle.  MetPy's sky_cover function produces this symbol when the sky cover value\n",
    "    is zero.  Here, I create a list of zeros, one for each station, and then I pass it into the plot_symbol function to get\n",
    "    the open circle center symbol.\n",
    "    \"\"\"\n",
    "    num_of_stations = len(obs_data[\"latitude\"].values)\n",
    "\n",
    "    zeros = np.zeros(num_of_stations, dtype=int)\n",
    "    \n",
    "    stationplot.plot_symbol('C', zeros, sky_cover)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Switching to the GFS analysis, first we want to smooth the geopotential height data to make them easier to analyze.  \n",
    "    Setup the Gaussian filter for the geopotential heights ('gh'). Choose an appropriate smoothing value for these data.\n",
    "    \"\"\"\n",
    "    smooth_heights = \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    We can now isopleth the smoothed geopotential height data.  In the statement below, add styling information to make the contours easier to read.\n",
    "    \"\"\"\n",
    "    cont_p = plt.contour(model_data[\"longitude\"].values, model_data[\"latitude\"].values, smooth_heights, np.arange(0,10000,60), transform=crs.PlateCarree())\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Every contour plot needs labels for each contour, so we add contour labels below.  Add styling information to make the contour labels easier to read.\n",
    "    \"\"\"\n",
    "    ax.clabel(cont_p, cont_p.levels, fmt=lambda v: format(v, '.0f')\n",
    "     \n",
    "\n",
    "    \"\"\"\n",
    "    Let's add symbols denoting minima (lows) and maxima (highs) in the gridded geopotential height data.\n",
    "    The function below takes our gridded data, find the minimum and maximum points, and then plots\n",
    "    the appropriate symbol with the value.\n",
    "    \n",
    "    The first argument is our axes variable.\n",
    "    The second and third arguments are our longitude and latitude variables, respectively.\n",
    "    The fourth argument is our gridded geopotential height data.\n",
    "    The fifth argument says if we are looking for lows (min) or highs (max).\n",
    "    The sixth argument says how much of a spatial buffer to use when searching for highs and lows.  The function will be more sensitive to smaller-\n",
    "    scale highs and lows (thus leading to more highs and lows being plotted) when this value is smaller. The opposite is true when this value is larger.\n",
    "    You will have to experiment with different values to find one that displays the appropriate amount of highs and lows (i.e., reflecting synoptic-scale\n",
    "    features) rather than every high and low point in the data.\n",
    "    The seventh argument is the size of the high or low symbols.\n",
    "    The final argument is the data's coordinate system.\n",
    "    \"\"\" \n",
    "    plot_maxmin_points(ax, model_data[\"longitude\"].values, model_data[\"latitude\"].values, smooth_heights, \"min\", 65, textsize=20, transform=crs.PlateCarree())\n",
    "    plot_maxmin_points(ax, model_data[\"longitude\"].values, model_data[\"latitude\"].values, smooth_heights, \"max\", 65, textsize=20, transform=crs.PlateCarree())\n",
    "    \n",
    "              \n",
    "    \"\"\"\n",
    "    Finally, add an appropriate title for the map that shows what is plotted and the time at which the map is valid.\n",
    "    \"\"\"\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9b1172-48f8-49cc-b2a5-2ddfaea70f26",
   "metadata": {},
   "source": [
    "<br /><br />\n",
    "6. Finally, re-run the two functions we created to create a plot valid at 1200 UTC on July 28th, 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e15e2-c8d1-4100-b3df-45cc125e12eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae52ad7a-84e1-4540-b7dc-6c24150d2b21",
   "metadata": {},
   "source": [
    "### You have now completed the Python portion of the lab.  Be sure to submit the fully rendered Jupyter Notebook on GitHub when you are finished."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
